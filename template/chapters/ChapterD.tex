% !Mode:: "TeX:UTF-8"

\chapter{分层光网络下的并行路由优化算法研究}
\section{引言}
  随着视频流、云计算服务和移动应用的普及，互联网的流量不断增加[]，业务量的持续增长给互联网的传输带来了巨大的挑战，为了满足日益增长的容量要求，波分复用（WDM）系统已部署在骨干网络，其每个通道带宽高达40 GB/s或100 Gb/s。现在，400 Gb/s的带宽接口已经在实验室[2]实现，此外，为了满足不同的数据速率服务异构的流量类型，混合线路速率（10/40/100Gb/s）的WDM系统也已经部署。因此，WDM光网络视乎为大流量业务传输提供了一个既实际又高效的解决方案。
  然而，传统的WDM光网络严格遵循ITU-T的固定均匀间距和网格（通常为50）GHz或100千兆赫）[]，这样会导致低效的频谱利用率，比如，一个较大的波长可能会被分配给一个低速率的业务，即使这个业务根本就不能占满整个波长。很明显，传统WDM光网络的不灵活和粗粒度的带宽控制会导致显著的频谱浪费，限制了提高其网络容量的潜力。
  为了应对WDM网络的低敏捷性和频谱浪费问题，近年来,弹性光网络(EON)的架构被提出，在EON架构中，存在细粒度的带宽间隙（比如，12.5GHZ），他比WDM网络所遵循的ITU标志的50GHZ或者100GHZ的带宽粒度要小很多，而且，这些带宽间隙可以根据需要被组合在一起以提供更宽的通道。所以为了提高带宽利用率，在EON中存在混合速率，每个速率的业务需要不同数量的频谱间隙数量。理论上，EONs能够灵活地提供各种速率，但是在实际中，EONs却可能只含有很少的速率种类，这主要是因为：第一，随着频谱的增加，频谱碎片和管理复杂度将显著增加。第二，实际的EON从较低的线路费率升级到更高的线路费率，并存大量速率的情况已经很少见了。
  为了在EON网络中加入业务，控制平面必须在网络中找到一条路径，同时，还需要在此路径上的链路上分配足够的频谱带宽，来创建一个合适的端到端光路连接，这被称为路由和频谱分配（RSA）问题，EONs中的RSA问题比传统的在WDM网络中的路由和波长分配（RWA）问题更具有挑战性，传统的RWA解决方案[][]在EONs中已经变得不再适应了。在EONs中一个业务需求可能需要多个连续的频谱间隙，而且由于缺少全光谱转换器，每条光连接的频谱从它的源节点到它的目的节点 ,在所经过的链路上保持不变，这被称为频谱连续性限制。
  根据流量模式，RSA问题可以进一步分为静态RSA问题和动态RSA问题。静态的RSA问题出现在网络规划阶段，其中流量需求是已知的，这样可以离线计算出最优或者接近最优的RSA解，动态RSA问题是指在实时业务情况下光通路的路由选择和波长分配的优化问题，在动态RSA问题中，业务随机的到达和离开光网络，而且当业务到达网络时，控制平面需要在短时间内找到RSA解来安排业务。动态RSA问题比静态RSA问题更具有挑战性，因为业务需求随机到达和离开，网络状况随时发生变化，而且要求控制平面反应实时。
 链路代价表示路由路径选择这一条链路所需要的代价，链路代价可以设置为链路延迟，租用链路需要的费用等等，业务的路由代价表示业务路径经过的链路的代价总和，路由代价反应了路由路径的优劣程度，如果链路代价设置为延迟，则路由代价越小表示路由整体延迟较小，如果链路代价设置为1，则路由代价越小，表示路径经过的跳数越小，使用的链路资源越小。
 本章考虑在EONs中解决动态RSA问题，设计出带跳限约束下的基于分层图的动态路由优化算法来优化整体路由代价，分别考虑无权图和带权图上的算法GPU加速设计，GPU并行版本达到平均近6倍的算法加速比，实验与分层图上的传统算法比较，显示该算法过程在短时间内能够大量的优化路由代价，并且由于路由选择较优，使用网络资源较少，最终网络阻塞率表现也有显著的提高，实现了快速的路由代价优化和整体的阻塞避免。
\section{问题描述}
\subsection{EONs中动态RSA问题}
  在动态场景中，业务的到达时间和服务时间都是随机的，当业务到达网络时，SDN控制层需要找到可行的路径，并且为路径分配合适的频谱资源。由于EON的物理限制，RSA问题的解需要满足以下限制：
%\begin{enumerate}[(i)]
第一，传输距离限制：光信号的传输质量会随着传输距离的增加而下降，为了在目的点顺利恢复光信号，光链路的传输距离需要小于一个阈值$W_max$,为了简化设计，本文假设每一条链路的长度相同，都是一个单位，那么传输路径的跳数需要小于阈值$D_max$。
第二，频谱连续性限制：每条光连接的频谱从它的源节点到它的目的节点 ,在所经过的链路上保持不变。
第三，频谱不重叠限制：同一光纤链路中的频谱不能分配给不同的光路。
第四，频谱邻近限制：频谱邻近约束保证分配给一个光路径的频谱必须是一个连续的部分。
 此外，为了限制路径对网络频谱的资源使用，我们为路径加入跳限约束，论文[]中对网络加入跳限约束，使得整体上阻塞率降低，此外，后面将讨论，加入跳限约束后能够简化GPU上代码的实现，使得算法可以提前结束，节省同步标记。
\subsection{分层网络模型}
  论文[]中提出一种分层图模型来解决WDM网络中的路由和波长分配问题，分层图模型将路由选择和波长分配问题统一到一起来，使得RWA问题变得简化，这种分层图模型也可以很容易推广到EONs的RSA问题中。
  我们使用有向图$N(V,E)$表示物理网络拓扑，其中$V={v_1,v_2,...,v_N}$表示节点集合，$E={e_1,e_2,e_3,...,e_M}$表示边集合，$e_k=(i_k,j_k)$表示边的头节点为$v_{i_k}$，边的尾节点为$v_{j_k}$。假设所有光链路具有相同的频谱范围$W=(F_{start},F_{end})$,其中$F_{end}-F_{start}=C$。EON所支持的速率集合为$R$,比如，$R={40Gb/s,100Gb/s,400Gb/s}$,每一种速率$r\in R$需要一个特定的频谱宽度$b_r GHz$。一个源节点为$s$,目的节点为$t$,速率为$r Gb/s$的业务被表示为$TD(s,t,r)$。
  下面我们讨论分层图的产生过程，假设第一个速率的为$r$的业务$TD_r(s,t)$到达网络,我们从可用的频谱切割出一块频谱大小为$b_r$的连续带宽分配给速率为$r$的业务，假设这块频谱的起始频率为$fs_{（r,1）}$，终止频谱为$fe_{（r,1）}$，那么$fe_{（r,1）}-fs_{（r,1）}=b_r$，我们把所有物理链路上频谱范围$(fs_{（r,1）},fe_{（r,1）})$,从链路上“割”下来，把“割”下来的部分组成一个新的虚拟网络$N^{（r,1）} (V^{（r,1）},E^{（r,1）}）$，在这个新的网络中每条链路的频谱范围都是$(fs_{（r,1）},fe_{（r,1）})$,这样切割下来之后，原来的物理网络的频谱范围更新为$(F_{start}+b_r,F_{end})$。
  然后在这个复制出来的图上为业务求一条最短路径$p$，那么容易知道路径$p$一定满足约束2,3,4,这样问题被简化为单纯的路由问题。要注意的是，这个虚拟图上频谱不能再分配给其他速率为$r'$的业务$TD_r'(s',t')$,即使$b_r'<b_r$,这是因为这样会产生大量的频谱碎片，使得频谱利用率下降，阻塞率降低，并且这样会使得问题变得更加复杂化，所以这些分割出来给速率$r$的频谱，将继续被分配给速率为$r$的业务。当下一个速率为$r$的业务$TD_r (s'',t'')$到达网络后，他首先在图$N^{ （r,1）}(V^{（r,1）},E^{（r,1）}）$中寻找路径，如果找到合适的路径则加入网络并且更新路径链路的可用频谱为0；反之，如果他在图$N^{（r,1）} (V^{（r,1）},E^{（r,1）}）$中没有找到合适的路径，那么算法会重新去”切割“物理拓扑得到虚拟网络$N^{（r,2）} (V^{（r,2）},E^{(r,2)}）$，这样随着大量业务的动态的到达和离去，会产生大量的虚拟图，频谱资源已经大量地分布在各个虚拟图中，我们把这些虚拟图叫做分层图（layered Graph），现在RSA问题转化为在分层图中求解路由的问题，问题被简化。
  下图表示分层图示意，原图被切割成一个分层图集集合$L$，$L_i \in L$表示速率$i$的分层图集，如图所示，速率$k$的一共有$|L_k|$个图副本,每个子分层图占用频谱$(fs_{（r,1）},fe_{（r,1）})$，图中，点$v_i^{(r,l)}$表示速率$r$的第$l$层图上的第$i$号点。
$f_{()}$
\begin{figure*}
\setlength{\belowcaptionskip}{-0.5cm}
  \begin{center}
    {\includegraphics[width=1 \textwidth]{figures/LAYER.pdf}}
    \end{center}
  \caption{{\footnotesize{分层图示意}}}
  \label{layer}
\end{figure*}
\section{主要优化流程}
  根据前面的讨论，当一个速率为$r$的业务$TD_r(s,t)$到达网络时，一共有$L_r$个分层平面都可以用于此业务，也就是说如果在这些图当中都能为业务找到合适的路径的话，那么业务就有$L_r$条路径可供选择，我们可以选择代价最小的一条来优化路由。进一步，当有一批速率为$r$的业务集合$TD_r$到达网络时，如果大家都选择同一层加入的话，会出现大量的冲突，而且路由代价也会很大，但是由于现在有多个分层图平面可以选择，每个业务都有$L_r$条路径可以选择，这就给路由优化提供了可能，不同的业务需求可以选择不同层上的路径来进行路由，以使得总体路由代价减小，节省网络频谱资源，从而优化阻塞率。本节提出一个基于分层图的动态RSA优化算法流程，算法流程图如下所示：
 \begin{figure*}
\setlength{\belowcaptionskip}{-0.5cm}
  \begin{center}
    {\includegraphics[width=1 \textwidth]{figures/bbprocess.pdf}}
    \end{center}
  \caption{{\footnotesize{算法优化流程}}}
  \label{bblayer}
\end{figure*}
 当一批业务到达网络时，对每一个业务在其对应速率的层上求出大量的备选路径，这个过程计算量较大，但是每一个拓扑层是独立的，所以可以采用并行算法来进行加速设计，后面**将讨论无权图和有权图上的两种基于GPU的路由加速算法来加速这个步骤，当备选路径都求出来了之后采用一种快速路径选择算法来把业务安排进网络，这个步骤采用一种简单贪心的启发式算法，由于备选路径较多，实验发现这种简单的贪心算法已经可以很好的优化路径代价了。当业务的路径确定后，如果每个业务都能加入到网络，那么本轮算法结束，如果还有剩余的业务没有被安排进网络，需要判断业务的备选路径集合是否为空，如果为空，则说明所有层都不能为业务求出路径，业务将被阻塞；反之，如果业务的备选路径集合不是空，则说明业务是因为和其他业务的路径冲突而导致不能被安排进网络，分层图中可能还存在其他可用路径，所以需要重新在分层图中计算路径，算法回到步骤二，对这些业务进行重新计算。
 步骤一的具体算法将在**结束，这里介绍步骤二的快速优化算法，快速优化算法的主要思想是根据求出来的备选路径为每个业务选择路径以使得整体路径代价最小，由于动态RSA环境下需要在短时间内安排好路径，所以为了提高计算速度，这里采用一种简单快速的贪心算法来进行解决。算法步骤如下所示：
\begin{algorithm}[htb] 
\caption{路径安排算法} 
\label{arrange} 
\begin{algorithmic}[1] 
\Require 
$N(v,E)$:分层图;
$P$:备选路径集合;
$TD$:业务需求集合;
\Ensure 
$AP$:加入业务的路径集合; 
\For{$T \in TD$}
\State {对$P_T$中的路径按照路径的代价进行降序排序}
\EndFor
\State {对$T$按照$P_T$中的最小路径代价进行排序}
\For{$T \in TD$}
\For{$p \in P_T$}
\If{路径$p$所对应分层图上的相应链路没有被占用}
	\State{把$p$加入到$AP$中，并更新$p$所对应的分层网络上的链路，跳出for循环，以继续为下一个业务选路}
\EndIf
\EndFor
\EndFor
\end{algorithmic} 
\end{algorithm}
 算法开始对每个业务的备选路径按照其代价进行降序排序，也就是每个业务优先会选择代价较低的备选路径。然后，再对业务按照其最小代价的路径进行排序，这样保证优先考虑代价小的业务。然后开始加入业务到网络，对每一个业务，遍历其已经排序好的备选路径，如果在相应分层图上路径包含的链路都是空闲的，则加入业务到网络中，更新分层图上的相应链路为占用状态，把这个路径$p$加入到集合$AP$中。最后算法输出路径集合$AP$,算法结束。
\section{无权图情况下的GPU算法设计}
  无权图情况下，路由的代价就是路径的跳数，跳数越少说明占用的网络资源越少，尽量优化路径的跳数可以节省网络资源，进一步的降低动态情况下的网络的阻塞。无权图情况下的路由算法一般使用BFS（宽度优先搜索）算法进行求解，BFS算法从目的节点最近的点开始，一层一层的进行扩展直到找到目的节点，每扩展一层跳数增加一条，扩展一层需要遍历大量的边，这些边的扩展操作是相互独立的，所以为算法提供了并行设计的可能性，在加上不同速率不同层上的路由求解上的并行，总体并行粒度是很大的，下面分别对不同的并行层次的设计进行讨论。
\subsection {相同速率业务的并行}
  如下图所示，对速率都为$r$的一批业务，在其可用的每个分层图上并行进行计算，在每个分层图上，具有相同源节点的业务组成业务组，因为他们的路径可以一起计算，对每一个业务组，在GPU上开辟$|E|$个线程对每一条边进行扩展操作，那么整个过程的的并行粒度为$|L_r|*|D_r|*|E|$,其中$|D_r|$为速率为$r$的业务组数量。
 \begin{figure*}
\setlength{\belowcaptionskip}{-0.5cm}
  \begin{center}
    {\includegraphics[width=1 \textwidth]{figures/bfs.pdf}}
    \end{center}
  \caption{{\footnotesize{bfs并行示意图}}}
  \label{bfs}
\end{figure*}
\subsection{不同速率间业务的并行}
  由于动态业务情况下每次到达网络的业务数和速率情况都是变化的，不同速率之间业务的并行不容易直接实现在一个kernel中进行，我们采用GPU提供的流并行进行并行设计。如下图所示：
 \begin{figure*}
\setlength{\belowcaptionskip}{-0.5cm}
  \begin{center}
    {\includegraphics[width=1 \textwidth]{figures/hbfs.pdf}}
    \end{center}
  \caption{{\footnotesize{bfs流并行示意图}}}
  \label{bfssteam}
\end{figure*}
 我们为每一个速率建立一个stream来负责这个速率的业务计算，假设业务一个有$|R|$个不同速率，那么需要建立$|R|$个stream，多个kernel同时执行，充分利用GPU的SMIT资源，当SIMT资源足够时，每个kernel将并行执行，当SIMIT不足时，不同的kernel之间可以进行快速的切换，以达到隐藏延迟的效果。另外，每个速率的内部业务计算的并行如（）所讨论的那样。
\subsection{GPU上kernel设计}
  和**中讨论不一样，在bfs的并行中不会存在前驱节点更新的同步问题，但是，我们依然需要两个kernel函数，这是因为扩展kernel需要执行多次，如果扩展和更新同时执行，那么更新也会执行多次，这会增多内存访问，所以我们把两个操作分成两个kernel，一个$kernel_bfs_extend$进行边的扩展操作，一个$kernel_bfs_update$进行前驱节点的更新操作，其中$kernel_bfs_extend$需要多次调用，但是$kernel_bfs_update$只需要在最后执行一次。
\begin{algorithm}[t]
\begin{algorithmic}[1]
\caption{\small{kernel\_bfs\_extend($E$, $Dist$,$rid$,$round$)}}
\label{KernelBFS}
\State {$bid \leftarrow$ block ID}
\State {$tid \leftarrow$ thread ID}
\State {用$(bid,tid,rid)$ 映射到边的标号$eid$}
\State {用$(bid,tid,rid)$ 映射到分层图标号$lid$}
\State {$e \leftarrow E[gid][eid]$}
\If {$e.avaliable==-1$}
\State{return}
\EndIf
\State {用$(bid,tid,rid)$ 映射到的源点标号$sid$}
\If{$Dist[lid][sid][e.head]>round $\&\&$ Dist[lid][sid][e.tail]+1==round$}
\State {$Dist[gid][sid][e.head] \leftarrow round$}
\EndIf
\Return
\end{algorithmic}
\end{algorithm} 
 在$kernel_bfs_extend$中，输入$E$是所有的分层图的边所组成的集合，$Dist$是预先分配的距离标记数组，他是一个三维数组，第一维表示当前距离数组对应的分层图标号，第二维度表示源节点，第三维度表示目的节点，比如$Dist[3][10][5]$=4表示在第3个分层图上，点10到3的距离为4，初始时,除了源节点距离被初始化为0之外，其他的距离都被初始化为无穷大。$rid$表示当前kernel负责的计算的业务速率标号，他是区分不同流的标记，$rid$不同表示执行kernel的流不同。$round$表示当前扩展的层数，由于BFS是一层一层进行扩展操作，我们需要记录当前层数来决定哪些边需要扩展。算法开始时先进行一系列映射操作，将线程映射到边标号$eid$,当前所在分层图标号$lid$,以及源节点标号$sid$。由于动态情况下，边的可用状态可能发生变化，找到边之后，需要判断这条边是否可用，如果不可用则返回。接着判断当前边是否可以进行扩展操作，如果尾节点已经更新过了（$Dist[lid][sid][e.head]<=round$)，则不能再更新了，反之，还需要判断头节点是否上一次扩展层的节点（$Dist[lid][sid][e.tail]+1==round$），如果是的话，那么就更新尾节点的距离为当前扩展层$round$。
\begin{algorithm}[t]
\begin{algorithmic}[1]
\caption{\small{kernel\_bfs\_update($E$, $Pre$,$rid$)}}
\label{KernelBFS}
\State {$bid \leftarrow$ block ID}
\State {$tid \leftarrow$ thread ID}
\State {用$(bid,tid,rid)$ 映射到边的标号$eid$}
\State {用$(bid,tid,rid)$ 映射到分层图标号$lid$}
\State {$e \leftarrow E[gid][eid]$}
\If {$e.avaliable==-1$}
\State{return}
\EndIf
\State {用$(bid,tid,rid)$ 映射到的源点标号$sid$}
\If{$Dist[lid][sid][e.head]==Dist[lid][sid][e.tail]+1$}
\State {$Pre[gid][sid][e.head] \leftarrow e.tail$}
\EndIf
\Return
\end{algorithmic}
\end{algorithm} 
 在$kernel_bfs_update$中，其主要逻辑和$kernel_bfs_extend$一样，在进行更新判断的时候，判断当前边的头节点是否是尾节点的上一层（Dist[lid][sid][e.head]==Dist[lid][sid][e.tail]+1）如果是的话，那么头节点就有资格作为尾节点的前驱节点，于是进行前驱更新操作。
  介绍完了两个kernel之后，下图为整个并行BFS的算法流程：
\begin{algorithm}[t]
\begin{algorithmic}[1]
\caption{{并行bfs计算}}
\label{ParaSPC}
\Require
	 业务需求集合$TD$;
      分层图链路集合$E$;
\Ensure {业务需求的最短路径集合$P$}
\State {将业务根据速率和源节点重新组合成业务分组集合$D$}
\For {$D_r \in D$}
\For {$d_{rs} \in D_r$}
\For {$l \in L_r$}
\For {$v \in V$}
\If {$v==s$}
\State {$Dist[l][s][v]\leftarrow$ 0}
\Else
\State {$Dist[l][s][v]\leftarrow \infty $}
\EndIf
\State {$Pre[l][s][v]\leftarrow -1 $}
\EndFor
\EndFor
\EndFor
\EndFor
\State {新建$|R|$个流，组成集合$S$}
\State {$round \leftarrow$ 1}
\While{$round<=W_{max}$}
\For{r in R}
\State {在流$S_r$上发射 kernel\_bfs\_extend($E$, $Dist$,$r$,$round$)}
\EndFor
\State{round=round+1}
\EndWhile
\For{r in R}
\State {在流$S_r$上发射 kernel\_bfs\_update($E$, $Dist$,$r$,$round$)}
\EndFor
\State {根据前驱数组$Pre$重建路径，然后把路径加入到集合$P$}
\Return {$P$}
\end{algorithmic}
\end{algorithm}
 算法开始时先将业务按照速率的不同进行划分，再将业务按照源节点的不同划分成不同的业务组集合$D$，比如，$D_r \in D$表示速率为$r$的业务组集合，$d_{rs} \in D_r$表示速率为$r$的源节点标号为$s$的业务组。划分好业务组之后，就开始初始化距离数组，将速率对应的所有分层图上的源节点距离初始化为0，这是一个三层的for循环，第一层遍历速率标号，第二层遍历源节点标号，第三层遍历速率所对应的分层图标号；初始化$Dist$数组后，在发射kernel之前需要先新建$|R|$个GPU流，不同的流将对不同速率的业务进行计算。$round$为扩展的层数标记，开始时$round$初始化为1。while循环中进行扩展操作，其中$W_{max}$为跳数限制，最大跳数不能超过$W_{max}$,每一次扩展操作只会使得路径长度增加一跳，所以最多只能循环$W_{max}$次。while循环中for循环用来发射不同的流，因为发射不同流的kernel是异步操作，for循环不会去等待上kernel结束了才去执行下一个kernel，所以可以认为所有kernel都是同时间发射的。
while循环结束后，算法发射$kernel\_bfs\_update$进行前驱节点记录操作，最后根据这些前驱信息，算法重新恢复出路径，组成路径集合$P$，算法结束。
\section{带权图情况下的GPU算法设计}  
  在实际应用场景中，我们常常需要将不同的链路设置为不同的代价，因为链路的延迟，租用费用可能不同，所以有必要考虑链路带权情况下的优化设计，算法优化的目标是业务使用的链路总体代价最小化，为了简化问题模型，本节只讨论链路代价为正值的情况。本节将逐步分析和设计适用于带权图的分层网络GPU并行算法。
\subsection{带跳数限制的最短路算法}
  带跳数约束的BFS路由，由于没有考虑链路的权重差异，把所有链路的权重看作一样，所有BFS路由的优化目标就是跳数，BFS就是寻找跳数最短的路径，跳数约束只是使得BFS算法提前结束。但是在带权的链路情况下，路由的优化目标是最小化链路代价和，也就是寻找一条代价最小的满足跳数约束的路径，跳数越短并不意味则代价越小，代价越小也不意味着跳数越小，这使得带权情况下比无权情况更加复杂。
  为了说明带权带跳数约束下的路由算法，我们介绍一些符号，在图$N(V,E)$中，有点$i \in V$,和点$j \in V$，假设集合$P_{ijk}$表示点$i$到点$j$的所有跳数为$k$的路径所组成的集合，设$p_{ijk}^*$为集合$P_{ijk}$当中代价最小的那一条路径，即$p_{ijk}^* =\arg\min\limits_{p \in P_{ijk}}\{Price\_Of(p)\}$，我们设最小代价数组为$Price$，$Price$为三维数组，其中$Price[i][j][k]=Price\_Of(p_{ijk}^*）$，即$Price[i][j][k]$表示为$p_{ijk}^*$的代价，也就是说$Price[i][j][k]$表示$i$到$j$的跳数为$k$跳的最小代价路径的代价。对点$i$，边集合$PreE_i$点$i$的入边组成的集合，点集合$PreN_i$表示点$i$的入节点所组成的集合。
  有了上面的符号介绍后，假设业务的源节点为$s$，下面给出一个动态规划递推式，其中$w_{nj}$表示边$(n,j)$的代价大小：
\begin{equation}\label{dynamic}
\begin{split}
Price[i][j][k]
=\begin{cases}
\min\limits_{n \in PreN_i}{Price[i][n][k-1]+w_{nj}} & \text{if $k>0$}\\
0 & \text{if $k=0$ and $i=s $} \\
\infty &{otherwise}
\end{cases}
\end{split}
\end{equation}
 设$p_{ijk}^*$为点$i$到$j$的跳数为$k$的最小代价路径，由于点$j$的前驱节点只可能是那些属于集合$PreN_j$的点，点$j$的前驱边只可能是集合$PreE_j$中的某一条边，那么最优路径$p_{ijk}^*$中的第$k$条边一定属于集合$PreE_j$，于是递推式中我们遍历了这些边，另外，设经过边$e \in PreE_j$到达$j$的跳数为$k$的最优路径为$p_{ijk}^e$，那么根据Price的定义我们可以得到$Price\_Of(p{ijk}^e)=Price[i][e.head][k-1]+w_e$，其中，$e.head$表示边的头结点，也就是点$i$的对应于边$e$的前驱节点。那么最优路径$p_{ijk}^*=\arg\min\limits_{e \in PreE}{Price_Of(p_e)}$，相应的最优代价$Price[i][j][k]=\min\limits_{e \in PreE}{Price_Of(p_e)}$，也就是$\min\limits_{n \in PreN_i}{Price[i][n][k-1]+w_{nj}}$。注意边界情况下($k==0$)，由于除了源节点自己之外，源节点到其他节点的跳数不可能是零，所以开始时需要设置代价为无穷大，而源节点到他自己距离设置为0。
  上面的动态规划递推式可以求得一个点到任意点的跳数为1到$k$的最优路径，而我们是要求得在跳数限制下的最优代价路径，我们需要对求得的动态规划解进行处理，设二维数组$OPCost$表示跳数限制下的最优路由代价值，那么跳数限制约束下的点$i$到点$j$的最小代价路径的代价为$OPCost[i][j]$，可以得到下面的表达式：
\begin{equation}\label{best}
\begin{split}
OPCost[i][j]=\min\limits_{k \in W_{max}}{Price[i][j][k]}
\end{split}
\end{equation}
 假设满足跳限约束的最优代价路径为$p_{ij}^*$，假设路径$p_{ij}^*$的跳数为$h$，$h \in [1,W_{max}]$，显然$p_{ij}^*=p_{ijh}$，但是实际上我们并不知道$h$的值，所以我们从$[1,W_{max}]$对$h$进行遍历，那么$p_{ij}^*$肯定是其中代价最小的一条，所以$p_{ij}^*=\min\limits_{k \in W_{max}}{Price_Of(p_{ijk}^*)}$，同样，$OPCost[i][j]=\min\limits_{k \in W_{max}}{Price[i][j][k]}$。
 观察动态规划递推式，可以看到，在递推过程不会去记录路径，这样求得路径可能会经过重复的点，但是，最优路径$p_{ij}^*$中是不可能经过重复节点的，下面本文进行证明。首先，路径跳数$h<4$的路径是不可能经过重复的节点，我们讨论$h>=4$时的情况，如果路径重复经过了一个点，那么路径中一定存在一个环，如下图所示，这个存在环的路径为$L_1-L_2-L_3-L_2-L_4$，假设链路$L_2$的跳数为$h_2$，代价为$C_2$，由于链路的代价都是正数，所以$C_2>0$，那么存在一条跳数为$t=h-h_2$的，代价为$OPCost[i][j]-C_2$的由$i$到$j$的路径$L_1-L_2-L_4$，而这条路径的代价肯定小于等于$Price\_Of(p_{ijt})$，即$OPCost[i][j]-C_2<=Price\_Of(p_{ijt})<=OPCost[i][j]$，进一步得到$OPCost[i][j]-C_2<=OPCost[i][j]$，这与$C_2>0$矛盾，所以最优路径不可能经过重复的节点。
 \begin{figure*}
\setlength{\belowcaptionskip}{-0.5cm}
  \begin{center}
    {\includegraphics[width=1 \textwidth]{figures/circle.pdf}}
    \end{center}
  \caption{{\footnotesize{无环证明}}}
  \label{prof}
\end{figure*}
\subsection{并行层次}
\subsection{并行动态规划算法}
 上一节提出了动态规划模型，证明了算法的正确性，本节我们讨论这个动态规划算法在GPU上的并行设计框架，以及分层图和不同速率的并行层次设计。
 单个图上的动态规划的串行执行过程如下伪代码所示：
\begin{algorithm}[t]
\begin{algorithmic}[1]
\caption{{串行动态规划算法}}
\Require
	 点的入边集合$PreE$;
      点的入点集合$PreN$;
	 源节点$s$;
\Ensure {最优代价数组$Price$;最优前驱节点数组$Pre$;}
\For {$k \in [1,W_{max}]$}
\For {$v \in V$}
\State {Price[s][v][k]=$\min\limits_{n \in PreN_v}{Price[s][n][k-1]+w_{nv}}$}
\State {Pre[i][j][k]=$\arg\min\limits_{n \in PreN_v}{Price[s][n][k-1]+w_{nv}}$}
\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}
  算法循环$W_{max}$次，每一次循环中对每一个点进行对应的$Price$数组进行更新，而这些更新操作是相互独立的，所以，可以进行并行设计，对每一个点的$Price$数组更新操作开辟一个线程进行计算，这个线程遍历当前点的前驱边，寻找最优的那一条前驱边，这里的并行粒度只有图的点数$|N|$，但是考虑到不同个业务和不同的分层图上计算也是并行的，总的并行粒度为$|N|*|D|*|R|$，这样需要开辟大量的线程，充分利用GPU上的SIMT计算资源。
  下面考虑单个速率情况下的并行框架，如下图所示，动态规划算法和BFS单个速率情况下的并行类似，只是BFS那里的对每一条边并行的扩展操作被替换成了对每一个点并行的$Price$数组更新操作。
 \begin{figure*}
\setlength{\belowcaptionskip}{-0.5cm}
  \begin{center}
    {\includegraphics[width=1 \textwidth]{figures/DRK.pdf}}
    \end{center}
  \caption{{\footnotesize{drk}}}
  \label{drk}
\end{figure*}
和**同样，对不同速率的业务，本文依然采用不同的流进行并行，其并行过程如下所示：
 \begin{figure*}
\setlength{\belowcaptionskip}{-0.5cm}
  \begin{center}
    {\includegraphics[width=1 \textwidth]{figures/BBK.pdf}}
    \end{center}
  \caption{{\footnotesize{BBK}}}
  \label{prof}
\end{figure*}
\subsection{GPU上kernel设计}
 动态规划的GPU代码设计如下：
\begin{algorithm}[t]
\begin{algorithmic}[1]
\caption{\small{kernel\_dynamic\_update($PE$,$rid$,$k$)}}
\label{KernelDynamic}
\State {$bid \leftarrow$ block ID}
\State {$tid \leftarrow$ thread ID}
\State {用$(bid,tid,rid)$ 映射到边点的标号$nid$}
\State {用$(bid,tid,rid)$ 映射到边源节点的标号$sid$}
\State {用$(bid,tid,rid)$ 映射到分层图标号$lid$}
\For {$e \in PE[lid][nid]$}
\If{$e.avalible>0$}
\If {$Price[lid][sid][nid][k]<Price[lid][sid][e.s][k-1]+e.weight$}
\State{$Price[lid][sid][nid][k]=Price[lid][sid][e.s][k-1]+e.weight$}
\State{$Pre[lid][sid][nid][k]=e.s$}
\EndIf
\EndIf
\EndFor
\Return
\end{algorithmic}
\end{algorithm} 
 在$kernel_dynamic_update$中，输入$PE$是一个二维的集合数组，比如，$PE[2][3]$表示第2个分层图上点3的入边集合。$Price$是预先分配的代价数组，他是一个三维数组，第一维表示当前代价数组对应的分层图标号，第二维度表示源节点，第三维度表示目的节点，第四维度表示路径的跳数，比如$Price[4][3][10][5]$=7表示在第4个分层图上，点3到10的跳数为5的最优路径代价为7，初始时,当跳数等于0时，除了源节点代价被初始化为0之外，其他的距离都被初始化为无穷大。
$Pre$数组是前驱数组用以记录前驱信息来恢复路径，$Pre$数组和$Price$数组一样，是一个四维数组，$Pre[4][3][10][5]$=50表示在第4个分层图上，点3到10的跳数为5的最优路径的前驱节点(也就是路径上的倒数第二个点)为点50。$rid$表示当前kernel负责的计算的业务速率标号，他是区分不同流的标记，$rid$不同表示执行kernel的流不同。$k$表示当前扩展的层数，也就是跳数。算法开始时先进行一系列映射操作，将线程映射到点标号$eid$,当前所在分层图标号$lid$,以及源节点标号$sid$，映射完成后就可以进行Price数组的更新了，也就是要去寻找最优的入边，算法遍历点的所有入边，由于动态情况下，边的可用状态可能发生变化，找到边之后，需要判断这条边是否可用，如果不可用则跳过这条边，反之，就判断更新条件是否成立($Price[lid][sid][nid][k]<Price[lid][sid][e.s][k-1]+e.weight$)，如果条件成立则说明这条入边比之前的要好，经过这条边到达当前点的路径代价更小，所有要更新Price数组，同时为了后面恢复路径需要记录前驱信息在数组$Pre$中。
\begin{algorithm}[t]
\begin{algorithmic}[1]
\caption{{并行动态规划的计算}}
\label{ParaSPC}
\Require
	 业务需求集合$TD$;
      各个分层图前驱链路集合$PE$;
\Ensure {业务需求的最短路径集合$P$}
\State {将业务根据速率和源节点重新组合成业务分组集合$D$}
\For {$D_r \in D$}
\For {$d_{rs} \in D_r$}
\For {$l \in L_r$}
\For {$v \in V$}
\If {$v==s$}
\State {$Price[l][s][v][0]\leftarrow$ 0}
\Else
\State {$Price[l][s][v][0]\leftarrow \infty $}
\EndIf
\State {$Pre[l][s][v][0]\leftarrow -1 $}
\EndFor
\EndFor
\EndFor
\EndFor
\State {新建$|R|$个流，组成集合$S$}
\State {$k \leftarrow$ 1}
\While{$k<=W_{max}$}
\For{r in R}
\State {在流$S_r$上发射 kernel\_dynamic\_update($PE$,$rid$,$k$)}
\EndFor
\State{k=k+1}
\EndWhile
\State {根据前驱数组$Pre$重建路径，然后把路径加入到集合$P$}
\Return {$P$}
\end{algorithmic}
\end{algorithm}
 算法开始时先将业务按照速率的不同进行划分，再将业务按照源节点的不同划分成不同的业务组集合$D$，比如，$D_r \in D$表示速率为$r$的业务组集合，$d_{rs} \in D_r$表示速率为$r$的源节点标号为$s$的业务组。划分好业务组之后，就开始初始化代价数组，将速率对应的所有分层图上的跳数为0的源节点代价初始化为0，这是一个三层的for循环，第一层遍历速率标号，第二层遍历源节点标号，第三层遍历速率所对应的分层图标号；初始化$Price$数组后，在发射kernel之前需要先新建$|R|$个GPU流，不同的流将对不同速率的业务进行计算。$k$为扩展的跳数标记，开始时$k$初始化为1。while循环中进行扩展操作，其中$W_{max}$为跳数限制，最大跳数不能超过$W_{max}$，所以最多只能循环$W_{max}$次。while循环中for循环用来发射不同的流，因为发射不同流的kernel是异步操作，for循环不会去等待上kernel结束了才去执行下一个kernel，所以可以认为所有kernel都是同时间发射的。
\section{实验仿真分析}



